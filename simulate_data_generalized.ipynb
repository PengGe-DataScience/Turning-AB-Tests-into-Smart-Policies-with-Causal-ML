{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-20T12:15:53.037906Z",
     "start_time": "2025-10-20T12:15:50.997562Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T12:15:53.052104Z",
     "start_time": "2025-10-20T12:15:53.047836Z"
    }
   },
   "cell_type": "code",
   "source": "# set the working directory",
   "id": "e563799545ff123b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T12:15:53.061993Z",
     "start_time": "2025-10-20T12:15:53.057312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def simulate_data(n_samples=50_000, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Simulates a dataset with X (predictors), T (treatment), Y (outcome) where T affects Y\n",
    "    depending on X; then splits data into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    n_samples (int): Number of samples to generate.\n",
    "    test_size (float): Proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "    None: Saves the generated dataset to CSV files.\n",
    "    \"\"\"\n",
    "    # Set the random seed for reproducibility\n",
    "    rs = 2024\n",
    "    np.random.seed(rs)\n",
    "\n",
    "    # Generate random values for columns X1, X2, X3, X4\n",
    "    X1 = np.random.rand(n_samples)\n",
    "    X2 = np.random.rand(n_samples)\n",
    "    X3 = np.random.rand(n_samples)\n",
    "    X4 = np.random.rand(n_samples)\n",
    "\n",
    "    # Create column X5 to have a correlation of 0.3 with column X4\n",
    "    noise = np.random.rand(n_samples)\n",
    "    X5 = 0.3 * X4 + np.sqrt(1 - 0.3 ** 2) * noise\n",
    "\n",
    "    # Generate binary columns X6 and X7 with a probability of 0.2 for 1\n",
    "    X6 = np.random.choice([0, 1], size=n_samples, p=[0.8, 0.2])\n",
    "    X7 = np.random.choice([0, 1], size=n_samples, p=[0.8, 0.2])\n",
    "\n",
    "    # Generate binary column T with a 50% probability for 0 and 1\n",
    "    T = np.random.choice([0, 1], size=n_samples, p=[0.5, 0.5])\n",
    "\n",
    "    # Initialize column Y\n",
    "    Y = np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    # Create column Y based on T and some X columns,\n",
    "    # effectively creating treatment heterogeneities\n",
    "    for i in range(n_samples):\n",
    "        if T[i] == 1:\n",
    "            prob_Y = 0.30 \\\n",
    "                     - 0.04 * (X1[i] + X2[i]) \\\n",
    "                     + 0.16 * (X3[i] * X4[i]) \\\n",
    "                     - 0.02 * X5[i] \\\n",
    "                     + 0.02 * X6[i]\n",
    "        else:\n",
    "            prob_Y = 0.30\n",
    "\n",
    "        # Ensure the probability is within the range [0, 1]\n",
    "        prob_Y = min(max(prob_Y, 0), 1)\n",
    "\n",
    "        # Generate Y based on the calculated probability\n",
    "        Y[i] = np.random.choice([0, 1], p=[1 - prob_Y, prob_Y])\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'X1': X1,\n",
    "        'X2': X2,\n",
    "        'X3': X3,\n",
    "        'X4': X4,\n",
    "        'X5': X5,\n",
    "        'X6': X6,\n",
    "        'X7': X7,\n",
    "        'T': T,\n",
    "        'Y': Y\n",
    "    })\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=rs)\n",
    "    train_df.to_csv('data/train_data.csv', index=False)\n",
    "    test_df.to_csv('data/test_data.csv', index=False)\n",
    "    print(\"Data simulation complete. Files saved to data/train_data.csv and data/test_data.csv\")\n"
   ],
   "id": "a6d3baf2919ebf5b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# -------------------------------------------------------\n",
    "# Notes for generating above code to practical business A/B tests：\n",
    "#\n",
    "# (1) Intercept (baseline rate) choices\n",
    "# - The simulator uses a baseline probability of 0.30 (30% chance of \"any return shipment\").\n",
    "# - In real deployments, set this intercept based on your observed baseline metric: e.g., if your true return-shipment rate is ~12%, use 0.12.\n",
    "#\n",
    "# (2) Customize correlation between X5 and X4 in other business cases\n",
    "# - In retail/marketplace applications, features like \"cart value\", \"number of items\", \"eco-label count\", \"weekday\", or \"duplicates present\" are often correlated.\n",
    "# - The authors deliberately make X5 correlated with X4 to mimic realistic feature dependencies.\n",
    "#\n",
    "# Current default (used above):\n",
    "#   X5 = 0.3 * X4 + sqrt(1 - 0.3**2) * noise\n",
    "# This construction targets corr(X4, X5) ≈ 0.3 assuming X4 and 'noise' have similar scale.\n",
    "#\n",
    "# Why this works:\n",
    "# - With X5 = a\\*X4 + b*noise and X4 ⟂ noise, corr(X4, X5) = a / sqrt(a\\**2 + b**2) (if variances match).\n",
    "# - Hence, to target correlation ρ, a convenient choice is: a = ρ, b = sqrt(1 - ρ**2).\n",
    "#\n",
    "# --- TUNE HERE IF YOU WANT A DIFFERENT CORRELATION ---\n",
    "# Example A: Stronger correlation (≈ 0.7), i.e., X5 follows X4 more closely\n",
    "# a = 0.7\n",
    "# b = np.sqrt(1 - a**2)\n",
    "# X5 = a * X4 + b * noise\n",
    "#\n",
    "# Example B: Weaker correlation (≈ 0.1), i.e., X5 more independent from X4\n",
    "# a = 0.1\n",
    "# b = np.sqrt(1 - a**2)\n",
    "# X5 = a * X4 + b * noise\n",
    "#\n",
    "# (3) Clamping vs. using a logit/probit link\n",
    "# - The simulator clamps probabilities to [0,1] with min(max(prob_Y,0),1) as a safe shortcut.\n",
    "# - In applied analytics, prefer a smooth link function for probability outcomes:\n",
    "#     prob_Y = 1 / (1 + np.exp(-linear_index))     # logistic link\n",
    "#     linear_index = <your deterministic function of X and T>\n",
    "# - Benefits:\n",
    "#   * Predictions always in (0,1) without sharp truncation.\n",
    "#   * Better behaved gradients for optimization and interpretation.\n",
    "#\n",
    "# (4) Simulating continuous business KPIs (returns value / sales)\n",
    "# - Many core KPIs (returns value, AOV, sales) are continuous, skewed, and non-negative.\n",
    "# - To simulate these, replace the Bernoulli draw with a skewed non-negative distribution whose mean depends on X and T. Two common choices:\n",
    "#     (a) Log-normal:\n",
    "#         Y_value = np.random.lognormal(mean=mu, sigma=sigma)\n",
    "#         mu = <mean index as a function of X,T>         # e.g., mu = beta0 + f(X,T)\n",
    "#         sigma = <spread parameter, e.g., 0.5>\n",
    "#     (b) Gamma:\n",
    "#         Y_value = np.random.gamma(shape, scale)\n",
    "#         shape, scale = <set from desired mean/variance that depend on X,T>\n",
    "# - This lets you simulate:\n",
    "#     * Returns (value): non-negative, right-skewed\n",
    "#     * Sales / revenue: non-negative, right-skewed\n",
    "#     * AOV (average order value): similar properties\n",
    "#\n",
    "# Training tweak for econml CausalForestDML:\n",
    "# - If you switch to a continuous outcome, set:\n",
    "#     CausalForestDML(discrete_treatment=True, discrete_outcome=False, ...)\n",
    "# - Off-policy evaluation (IPS) and GATE logic still apply conceptually—you're now estimating treatment effects on continuous KPIs (e.g., expected returns value or sales).\n",
    "# ----------------------------------------------------------"
   ],
   "id": "2a0d76de1d947b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T12:15:53.673162Z",
     "start_time": "2025-10-20T12:15:53.061993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    simulate_data()"
   ],
   "id": "9e2a97158bec84d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data simulation complete. Files saved to data/train_data.csv and data/test_data.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
